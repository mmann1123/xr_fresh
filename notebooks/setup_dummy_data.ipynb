{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmann1123/miniconda3/envs/xr_fresh/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax is running on: gpu\n",
      "<xarray.DataArray 'random_sample-3cb28b1d9e661857cd5bc381741e7ab7' (time: 3,\n",
      "                                                                    band: 4,\n",
      "                                                                    y: 100,\n",
      "                                                                    x: 200)>\n",
      "dask.array<concatenate, shape=(3, 4, 100, 200), dtype=float64, chunksize=(1, 1, 50, 50), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * band     (band) <U5 'blue' 'green' 'red' 'nir'\n",
      "  * y        (y) float64 1.985e+03 1.955e+03 1.924e+03 ... -984.7 -1.015e+03\n",
      "  * x        (x) float64 1.015e+03 1.045e+03 1.075e+03 ... 6.985e+03 7.015e+03\n",
      "  * time     (time) <U2 't1' 't2' 't3'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "from sklearn_xarray import wrap, Target\n",
    "from sklearn_xarray.preprocessing import Splitter, Sanitizer, Featurizer\n",
    "from sklearn_xarray.model_selection import CrossValidatorWrapper\n",
    "from sklearn_xarray.datasets import load_wisdm_dataarray\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "sys.path.append('/home/mmann1123/Documents/github/xr_fresh/')\n",
    "from xr_fresh.transformers import Stackerizer \n",
    "\n",
    "\n",
    "nrows = 100\n",
    "ncols = 200\n",
    "row_chunks = 50\n",
    "col_chunks = 50\n",
    "\n",
    "data = da.random.random(size=(1, nrows, ncols), chunks=(1, row_chunks, col_chunks))\n",
    "\n",
    "def create_band(data, x, y, band_name):\n",
    "\n",
    "    return xr.DataArray(data,\n",
    "                        dims=('band', 'y', 'x'),\n",
    "                        coords={'band': [band_name],\n",
    "                                'y': y,\n",
    "                                'x': x})\n",
    "\n",
    "def create_coords(data, left, top, celly, cellx):\n",
    "    nrows = data.shape[-2]\n",
    "    ncols = data.shape[-1]\n",
    "    right = left + cellx*ncols\n",
    "    bottom = top - celly*nrows\n",
    "    x = np.linspace(left, right, ncols) + cellx/2.0\n",
    "    y = np.linspace(top, bottom, nrows) - celly/2.0\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = create_coords(data, 1000, 2000, 30, 30)\n",
    "\n",
    "src = []\n",
    "\n",
    "for time in ['t1', 't2', 't3']:\n",
    "\n",
    "    src_t = xr.concat([create_band(data, x, y, band) for band in ['blue', 'green', 'red', 'nir']], dim='band')\\\n",
    "                    .expand_dims(dim='time')\\\n",
    "                    .assign_coords({'time': [time]})\n",
    "    \n",
    "    src.append(src_t)\n",
    "\n",
    "src = xr.concat(src, dim='time')\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'random_sample-3cb28b1d9e661857cd5bc381741e7ab7' (\n",
      "                                                                    sample: 60000,\n",
      "                                                                    band: 4)>\n",
      "dask.array<transpose, shape=(60000, 4), dtype=float64, chunksize=(3000, 1), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * band      (band) <U5 'blue' 'green' 'red' 'nir'\n",
      "    land_use  (sample) <U6 'forest' 'forest' 'forest' ... 'forest' 'forest'\n",
      "  * sample    (sample) object MultiIndex\n",
      "  * x         (sample) float64 1.015e+03 1.015e+03 ... 7.015e+03 7.015e+03\n",
      "  * y         (sample) float64 1.985e+03 1.985e+03 ... -1.015e+03 -1.015e+03\n",
      "  * time      (sample) <U2 't1' 't2' 't3' 't1' 't2' ... 't2' 't3' 't1' 't2' 't3'\n",
      "----------------------\n",
      "[[0.65389768 0.65389768 0.65389768 0.65389768]\n",
      " [0.65389768 0.65389768 0.65389768 0.65389768]\n",
      " [0.65389768 0.65389768 0.65389768 0.65389768]\n",
      " ...\n",
      " [0.89369969 0.89369969 0.89369969 0.89369969]\n",
      " [0.89369969 0.89369969 0.89369969 0.89369969]\n",
      " [0.89369969 0.89369969 0.89369969 0.89369969]]\n",
      "['forest' 'forest' 'forest' ... 'forest' 'forest' 'forest']\n",
      "----------------------\n",
      "(60000, 4)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "land_use = np.tile( \"water\", (src.sizes[\"time\"], src.sizes[\"y\"], src.sizes[\"x\"]) ).astype(object)\n",
    "land_use[src.sel(band='green').values > 0.5] = \"forest\"\n",
    "land_use = land_use.astype(str)\n",
    "src.coords[\"land_use\"] = ([\"time\", \"y\", \"x\"], land_use)\n",
    "\n",
    "X = Stackerizer(stack_dims = ('x','y','time'), direction='stack').fit_transform(src)\n",
    "\n",
    "print(X)\n",
    "print('----------------------')\n",
    "print(X.values)\n",
    "print(X.land_use.values)\n",
    "\n",
    "print('----------------------')\n",
    "print(X.shape)\n",
    "print(X.land_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CrossValidatorWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m pl \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     11\u001b[0m     [ \n\u001b[1;32m     12\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m,  StandardScaler),  \u001b[38;5;66;03m# zscores , ?wrap if xarray.self required?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Since we want to use cross-validated grid search to find the best model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# parameters, we define a cross-validator. In order to make sure the model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# performs subject-independent recognition, we use a `GroupShuffleSplit`\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# cross-validator that ensures that the same subject will not appear in both\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# training and validation set.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mCrossValidatorWrapper\u001b[49m(\n\u001b[1;32m     25\u001b[0m     GroupShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m), groupby\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# The grid search will try different numbers of PCA components to find the best\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# parameters for this task.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     33\u001b[0m     pl, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca__n_components\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m]}\n\u001b[1;32m     34\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CrossValidatorWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "# pl = Pipeline(\n",
    "#     [  \n",
    "#        (\"sanitizer\", Sanitizer()),    # Remove elements containing NaNs.\n",
    "#        (\"featurizer\", Featurizer()),  # Stack all dimensions and variables except for sample dimension.\n",
    "#        (\"scaler\", wrap(StandardScaler)), # zscores , ?wrap if xarray.self required? \n",
    "#        (\"pca\", wrap(PCA, reshapes=\"feature\")), \n",
    "#        (\"cls\", wrap(GaussianNB, reshapes=\"feature\")),\n",
    "#     ]\n",
    "# )\n",
    "pl = Pipeline(\n",
    "    [ \n",
    "        (\"scaler\",  StandardScaler),  # zscores , ?wrap if xarray.self required?\n",
    "        (\"pca\", PCA),\n",
    "        (\"cls\", GaussianNB),\n",
    "    ]\n",
    ")\n",
    "##############################################################################\n",
    "# Since we want to use cross-validated grid search to find the best model\n",
    "# parameters, we define a cross-validator. In order to make sure the model\n",
    "# performs subject-independent recognition, we use a `GroupShuffleSplit`\n",
    "# cross-validator that ensures that the same subject will not appear in both\n",
    "# training and validation set.\n",
    "\n",
    "cv = CrossValidatorWrapper(\n",
    "    GroupShuffleSplit(n_splits=3, test_size=0.5), groupby=[\"time\"]\n",
    ")\n",
    "\n",
    "##############################################################################\n",
    "# The grid search will try different numbers of PCA components to find the best\n",
    "# parameters for this task.\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pl, cv=cv, n_jobs=-1, verbose=1, param_grid={\"pca__n_components\": [5,10]}\n",
    ")\n",
    "\n",
    "##############################################################################\n",
    "# The label to classify is the activity which we convert to an integer\n",
    "# representation for the classification.\n",
    "\n",
    "y = Target(\n",
    "    coord=\"land_use\", transform_func=LabelEncoder().fit_transform )(X)\n",
    "\n",
    "##############################################################################\n",
    "# Finally, we run the grid search and print out the best parameter combination.\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(\"Best parameters: {0}\".format(gs.best_params_))\n",
    "print(\"Accuracy: {0}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%% predict \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m yp \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m      3\u001b[0m yp \u001b[38;5;241m=\u001b[39m yp\u001b[38;5;241m.\u001b[39munstack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m yp\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mimshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "#%% predict \n",
    "yp = gs.predict(X)\n",
    "yp = yp.unstack(\"sample\")\n",
    "yp.sel(time='t1').plot.imshow()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (x: 200, y: 100, time: 3)>\n",
      "array([[['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ...,\n",
      "        ['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest']],\n",
      "\n",
      "       [['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ...,\n",
      "        ['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['water', 'water', 'water']],\n",
      "\n",
      "       [['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        ['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water'],\n",
      "        ['water', 'water', 'water']],\n",
      "\n",
      "       [['forest', 'forest', 'forest'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ...,\n",
      "        ['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['water', 'water', 'water']],\n",
      "\n",
      "       [['forest', 'forest', 'forest'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ...,\n",
      "        ['water', 'water', 'water'],\n",
      "        ['forest', 'forest', 'forest'],\n",
      "        ['water', 'water', 'water']]], dtype='<U6')\n",
      "Coordinates:\n",
      "    land_use  (x, y, time) <U6 'water' 'water' 'water' ... 'water' 'water'\n",
      "  * x         (x) float64 1.015e+03 1.045e+03 1.075e+03 ... 6.985e+03 7.015e+03\n",
      "  * y         (y) float64 1.985e+03 1.955e+03 1.924e+03 ... -984.7 -1.015e+03\n",
      "  * time      (time) object 't1' 't2' 't3'\n"
     ]
    }
   ],
   "source": [
    "#%% predict labels\n",
    "yp = gs.predict(X)\n",
    "yp.values = LabelEncoder().fit(X.land_use).classes_[yp]\n",
    "yp = yp.unstack(\"sample\")\n",
    "print(yp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr_fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
